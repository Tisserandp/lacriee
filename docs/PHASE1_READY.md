# Phase 1: Infrastructure BigQuery - Pr√™t √† Ex√©cuter

## ‚úÖ Mises √† Jour Effectu√©es

### 1. Configuration Environnement

**Ancien:** `beo-erp.ERPTables.*`
**Nouveau:** `lacriee.PROD.*`

- Dataset: `lacriee.PROD`
- R√©gion: `US` (multi-r√©gion)
- Table de r√©f√©rence: `CodesNames` (d√©j√† clon√©e)

### 2. Fichiers Cr√©√©s

```
scripts/
‚îú‚îÄ‚îÄ init_db.sql                   # ‚úÖ Cr√©ation des 3 tables + vues
‚îú‚îÄ‚îÄ transform_staging_to_prod.sql # ‚úÖ Logic ELT (staging ‚Üí prod)
‚îî‚îÄ‚îÄ README_EXECUTION.md           # ‚úÖ Guide complet d'ex√©cution
```

### 3. Optimisations Appliqu√©es

#### Partitionnement (Cost Optimization)
- `ProvidersPrices_Staging`: **PARTITION BY DATE(import_timestamp)**
- `ImportJobs`: **PARTITION BY DATE(created_at)**
- `UnknownProducts`: **PARTITION BY DATE(first_seen)**

**B√©n√©fice:** Les requ√™tes scannent uniquement les partitions n√©cessaires (jour, semaine, mois) au lieu de tout l'historique.

#### Clustering (Query Performance)
- `ProvidersPrices_Staging`: **CLUSTER BY vendor, date_extracted**
- `ImportJobs`: **CLUSTER BY vendor, status**
- `UnknownProducts`: **CLUSTER BY vendor, resolved**

**B√©n√©fice:** Donn√©es physiquement group√©es pour des filtres rapides sur vendor et status.

---

## üìã Checklist Pr√©-Ex√©cution

### V√©rifications Environnement

- [ ] `gcloud` CLI install√©
- [ ] Authentifi√© avec `gcloud auth login`
- [ ] Projet GCP configur√© correctement
- [ ] Dataset `lacriee.PROD` existe
- [ ] Table `CodesNames` existe et contient des donn√©es

### Commandes de V√©rification

```bash
# 1. V√©rifier authentification
gcloud auth list

# 2. V√©rifier projet actif
gcloud config get-value project

# 3. V√©rifier dataset existe
bq ls lacriee

# 4. V√©rifier CodesNames existe
bq query --use_legacy_sql=false '
SELECT COUNT(*) AS row_count, COUNT(DISTINCT Vendor) AS vendors
FROM `lacriee.PROD.CodesNames`
'
```

---

## üöÄ Ex√©cution Phase 1

### √âtape 1: Cr√©er les Tables

```bash
cd c:\Users\Tisse\OneDrive\Tisserandp\LaCriee

# Ex√©cuter le script d'initialisation
bq query --use_legacy_sql=false < scripts/init_db.sql
```

**Attendu:** Cr√©ation de 3 tables + 3 vues

### √âtape 2: V√©rifier les Tables

```bash
# Lister toutes les tables
bq ls --format=pretty lacriee.PROD

# Devrait afficher:
# - CodesNames (existant)
# - ProvidersPrices (existant ou cr√©√©)
# - ProvidersPrices_Staging (nouveau)
# - ImportJobs (nouveau)
# - UnknownProducts (nouveau)
# - v_daily_import_summary (vue)
# - v_products_to_map (vue)
# - v_failed_jobs (vue)
```

### √âtape 3: Test de Transformation

```bash
# Ins√©rer une ligne de test
bq query --use_legacy_sql=false '
INSERT INTO `lacriee.PROD.ProvidersPrices_Staging`
(job_id, vendor, date_extracted, product_name_raw, code_provider, price_raw, staging_key, processed)
VALUES
("test-abc-123", "laurent_daniel", CURRENT_DATE(), "SAUMON TEST", "LD_SAUMON_TEST", 35.00, "test-key-1", FALSE)
'

# Ex√©cuter la transformation
bq query \
  --use_legacy_sql=false \
  --parameter=job_id:STRING:test-abc-123 \
  < scripts/transform_staging_to_prod.sql

# V√©rifier le r√©sultat
bq query --use_legacy_sql=false '
SELECT * FROM `lacriee.PROD.ProvidersPrices`
WHERE job_id = "test-abc-123"
'

# ‚úÖ Attendu: 1 ligne ins√©r√©e avec ProductName normalis√© via CodesNames

# Nettoyer le test
bq query --use_legacy_sql=false '
DELETE FROM `lacriee.PROD.ProvidersPrices` WHERE job_id = "test-abc-123";
DELETE FROM `lacriee.PROD.ProvidersPrices_Staging` WHERE job_id = "test-abc-123";
'
```

---

## üìä Sch√©mas des Tables

### Table: ProvidersPrices_Staging

| Colonne | Type | Description |
|---------|------|-------------|
| job_id | STRING | UUID du job d'import |
| import_timestamp | TIMESTAMP | Horodatage insertion (pour partition) |
| vendor | STRING | laurent_daniel, vvqm, demarne, hennequin |
| date_extracted | DATE | Date des prix extraite du PDF |
| product_name_raw | STRING | Nom brut du produit |
| code_provider | STRING | Code fournisseur (ex: LD_SAUMON_E) |
| price_raw | FLOAT64 | Prix en EUR/kg |
| quality_raw | STRING | Qualit√©/calibre |
| category_raw | STRING | Cat√©gorie brute PDF |
| staging_key | STRING | Cl√© unique |
| processed | BOOLEAN | True si transform√© ‚Üí prod |
| processing_error | STRING | Message d'erreur √©ventuel |

**Partitionnement:** `DATE(import_timestamp)`
**Clustering:** `vendor, date_extracted`

### Table: ImportJobs

| Colonne | Type | Description |
|---------|------|-------------|
| job_id | STRING | UUID du job |
| filename | STRING | Nom du fichier upload√© |
| vendor | STRING | Fournisseur |
| file_size_bytes | INT64 | Taille du fichier |
| gcs_url | STRING | URL GCS du fichier archiv√© |
| status | STRING | started, parsing, loading, transforming, completed, failed |
| status_message | STRING | Message descriptif |
| created_at | TIMESTAMP | Cr√©ation du job |
| completed_at | TIMESTAMP | Fin du job |
| duration_seconds | FLOAT64 | Dur√©e totale |
| rows_extracted | INT64 | Lignes extraites |
| rows_loaded_staging | INT64 | Lignes en staging |
| rows_inserted_prod | INT64 | Lignes ins√©r√©es prod |
| rows_updated_prod | INT64 | Lignes mises √† jour prod |
| rows_unknown_products | INT64 | Produits non mapp√©s |
| error_message | STRING | Message d'erreur |
| error_stacktrace | STRING | Stack trace compl√®te |

**Partitionnement:** `DATE(created_at)`
**Clustering:** `vendor, status`

### Table: UnknownProducts

| Colonne | Type | Description |
|---------|------|-------------|
| vendor | STRING | Fournisseur |
| code_provider | STRING | Code produit |
| product_name_raw | STRING | Nom brut |
| first_seen | TIMESTAMP | Premi√®re d√©tection |
| last_seen | TIMESTAMP | Derni√®re d√©tection |
| occurrence_count | INT64 | Nombre d'occurrences |
| job_ids | ARRAY<STRING> | Jobs o√π d√©tect√© |
| sample_data | JSON | Exemple de donn√©es |
| resolved | BOOLEAN | True si mapp√© |
| resolved_at | TIMESTAMP | Date de r√©solution |
| mapped_to_code | STRING | Code CodesNames |
| notes | STRING | Notes utilisateur |

**Partitionnement:** `DATE(first_seen)`
**Clustering:** `vendor, resolved`

---

## üîç Vues Cr√©√©es

### v_daily_import_summary
Dashboard quotidien avec m√©triques par vendor:
- Total imports
- Successful/Failed counts
- Avg duration
- Total rows inserted/updated
- Unknown products count

### v_products_to_map
Liste des produits non mapp√©s tri√©s par:
- Occurrence count (DESC)
- Last seen (DESC)

### v_failed_jobs
Jobs √©chou√©s des 7 derniers jours avec:
- Error message
- GCS URL pour investigation
- Duration

---

## ‚ö†Ô∏è Points de Vigilance

### 1. Projet ID

Les scripts utilisent `lacriee.PROD` (dataset seulement).

Si votre projet GCP a un ID diff√©rent de "lacriee", les scripts fonctionneront quand m√™me car BigQuery utilise le projet actif par d√©faut (`gcloud config get-value project`).

**Pour expliciter le projet:**
```sql
-- Remplacer
`lacriee.PROD.TableName`
-- Par
`VOTRE_PROJET_ID.lacriee.PROD.TableName`
```

### 2. R√©gion US

Le dataset est en multi-r√©gion **US**. Si vous avez des contraintes RGPD ou latence Europe, contactez-moi pour adapter la r√©gion.

### 3. CodesNames

Le script suppose que `lacriee.PROD.CodesNames` existe d√©j√†. Si absent:

```bash
# V√©rifier
bq show lacriee.PROD.CodesNames

# Si erreur "Not found", la table doit √™tre cr√©√©e ou clon√©e
```

---

## ‚úÖ Validation Phase 1

Une fois l'ex√©cution termin√©e, v√©rifier:

1. **Tables cr√©√©es:** `bq ls lacriee.PROD` montre 3+ tables
2. **Vues cr√©√©es:** Les 3 vues apparaissent dans la liste
3. **Test transformation:** Le test INSERT/TRANSFORM/DELETE fonctionne
4. **Aucune erreur:** Logs propres sans erreurs BigQuery

**Si tout est OK:** Phase 1 ‚úÖ ‚Üí Passer √† Phase 2 (Services Python)

---

## üìû Support

Si erreurs lors de l'ex√©cution:

1. Copier le message d'erreur complet
2. Copier la commande qui a √©chou√©
3. V√©rifier les pr√©requis (auth, dataset, permissions)
4. Consulter `scripts/README_EXECUTION.md` section Troubleshooting
